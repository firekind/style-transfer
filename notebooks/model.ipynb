{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tsalib import dim_vars\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from style_transfer import losses\n",
    "\n",
    "B, C, H, W = dim_vars(\"Batch(B) Channel(C) Height(H) Width(W)\", exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor: nn.Sequential = vgg19(pretrained=True).features.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('0', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('1', ReLU(inplace=True))\n('2', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('3', ReLU(inplace=True))\n('4', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('5', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('6', ReLU(inplace=True))\n('7', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('8', ReLU(inplace=True))\n('9', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('10', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('11', ReLU(inplace=True))\n('12', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('13', ReLU(inplace=True))\n('14', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('15', ReLU(inplace=True))\n('16', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('17', ReLU(inplace=True))\n('18', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('19', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('20', ReLU(inplace=True))\n('21', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('22', ReLU(inplace=True))\n('23', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('24', ReLU(inplace=True))\n('25', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('26', ReLU(inplace=True))\n('27', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('28', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('29', ReLU(inplace=True))\n('30', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('31', ReLU(inplace=True))\n('32', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('33', ReLU(inplace=True))\n('34', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('35', ReLU(inplace=True))\n('36', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n"
    }
   ],
   "source": [
    "for layer in feature_extractor.named_children():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.40760392, 0.45795686, 0.48501961],  # subtracting the mean of imagenet, which VGG net is trained on\n",
    "        std=[1, 1, 1]\n",
    "    )\n",
    "])\n",
    "\n",
    "# postprocessing transform\n",
    "postprocess = transforms.Compose([\n",
    "    transforms.Normalize(\n",
    "        mean=[-0.40760392, -0.45795686, -0.48501961],  # adding back the mean subtracted before\n",
    "        std=[1, 1, 1]\n",
    "    ),\n",
    "    transforms.Lambda(lambda x: torch.clamp(x, min=0, max=1)),\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: nn.Sequential = nn.Sequential()\n",
    "conv_count: int = 0\n",
    "\n",
    "content_layers = ['conv_4']\n",
    "style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "last_layer_count = max(len(content_layers), len(style_layers))\n",
    "\n",
    "content_image = preprocess(Image.open(\"images/content.jpg\"))\n",
    "style_image = preprocess(Image.open(\"images/style.jpg\"))\n",
    "content_image = content_image.unsqueeze(0)\n",
    "style_image = style_image.unsqueeze(0)\n",
    "\n",
    "iterator = iter(feature_extractor)\n",
    "\n",
    "while conv_count < last_layer_count:\n",
    "    layer = next(iterator)\n",
    "\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        conv_count += 1\n",
    "        name = f\"conv_{conv_count}\"\n",
    "    elif isinstance(layer, nn.ReLU):\n",
    "        name = f\"relu_{conv_count}\"\n",
    "        layer = nn.ReLU(inplace=False)\n",
    "    elif isinstance(layer, nn.MaxPool2d):\n",
    "        name = f\"pool_{conv_count}\"\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        name = f\"batchnorm_{conv_count}\"\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown layer: %s\" % layer)\n",
    "    \n",
    "    model.add_module(name, layer)\n",
    "\n",
    "    if name in content_layers:\n",
    "        # getting feature map of content image generated upto this layer\n",
    "        feature_map = model(content_image)\n",
    "\n",
    "        # constructing content loss module\n",
    "        model.add_module(f\"content_loss_{conv_count}\", losses.ContentLoss(feature_map))\n",
    "    \n",
    "    if name in style_layers:\n",
    "        # getting feature map of content image generated upto this layer\n",
    "        feature_map = model(content_image)\n",
    "\n",
    "        # constructing content loss module\n",
    "        model.add_module(f\"style_loss_{conv_count}\", losses.StyleLoss(feature_map))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('conv_1', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('style_loss_1', StyleLoss())\n('relu_1', ReLU())\n('conv_2', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('style_loss_2', StyleLoss())\n('relu_2', ReLU())\n('pool_2', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('conv_3', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('style_loss_3', StyleLoss())\n('relu_3', ReLU())\n('conv_4', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('content_loss_4', ContentLoss())\n('style_loss_4', StyleLoss())\n('relu_4', ReLU())\n('pool_4', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('conv_5', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('style_loss_5', StyleLoss())\n"
    }
   ],
   "source": [
    "for layer in model.named_children():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitstyletransferconda8d27bbea1ec249bb9f16b711175dc8cb",
   "display_name": "Python 3.6.10 64-bit ('style-transfer': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}